# 回调函数共享数据
Callbacks

> This is the final chapter of the essential [Dash Fundamentals](/). The
> [previous chapter](/interactive-graphing) covered how to use callbacks with
> the dcc.Graph component. The [rest of the Dash documentation](/) covers
> other topics like multi-page apps and component libraries. Just getting
> started? Make sure to [install the necessary dependencies](/installation).


在[回调入门指南](/basic-callbacks)中解释的核心Dash原则之一是**Dash回调必须永远不会修改其作用域之外的变量**。
修改任何全局变量都不安全。本章解释了其中的原因，并提供了一些在回调之间共享状态的替代模式
## 为什么共享状态

在一些应用程序中，你可能有多个回调，这些回调依赖于昂贵的数据处理任务，比如进行数据库查询、运行模拟或下载数据

与其让每个回调运行相同的昂贵任务，不如让一个回调运行任务，然后将结果共享给其他回调

实现这一目标的一种方法是为一个回调提供[多个输出](/basic-callback):昂贵的任务可以完成一次，并立即在所有输出中使用。
例如，如果需要从数据库中查询一些数据，然后在图和表中显示，那么您可以使用一个回调来计算数据并创建图和表输出

但有时在一个回调中有多个输出并不是一个好的解决方案。例如，假设Dash应用程序允许用户选择日期和温度单位(华氏度或摄氏度)，然后显示当天的温度。
您可以有一个回调，通过将日期和温度单位作为输入来输出温度，但这意味着如果用户只是将华氏温度更改为摄氏度，则必须重新下载天气数据，这可能会很耗时。
相反，使用两个回调会更有效:一个回调获取

## Dash无状态

Dash被设计成一个无状态框架

无状态框架比有状态框架更具可扩展性和健壮性。您访问的大多数网站都运行在无状态服务器上

它们具有更高的可伸缩性,因为向应用程序添加更多的计算能力是微不足道的 为了扩展应用程序以服务更多的用户或运行更多的计算,在不同的进程中运行应用程序的更多 副本

在生产环境中，这可以用gunicorn的worker命令来完成

​```bash
gunicorn app:server --workers 8
```   

或者在多个Docker容器或服务器中运行应用程序，并在它们之间进行负载平衡

无状态框架更加健壮，因为即使一个流程失败，其他流程也可以继续服务请求。
在Dash Enterprise Kubernetes中，这些容器可以在单独的服务器甚至单独的区域上运行，从而提供了针对服务器故障的弹性

使用无状态框架，用户会话不会与服务器进程一一对应。每个回调请求都可以在任何可用的进程上执行。
`gunicorn`将检查哪个进程没有忙于运行回调，并将新的回调请求发送给该进程。这意味着，只要这些请求不是在同一时间发生(通常不是)，几个进程就可以平衡10个或100个并发用户的请求

 **Sign up for Dash Club** → Two free cheat sheets plus updates from Chris
Parmer and Adam Schroeder delivered to your inbox every two months. Includes
tips and tricks, community apps, and deep dives into the Dash architecture.
_[Join now](https://go.plotly.com/dash-
club?utm_medium=dash_docs&utm_content=sharing-data-between-callbacks)_.

## 为什么全局变量会破坏你的应用

Dash旨在在多用户环境中工作，其中多人同时查看应用程序并具有**个独立会话
如果你的应用使用并修改了一个全局变量，那么一个用户的会话可能会将该变量设置为影响下一个用户会话的某个值
Dash还被设计成能够与多个工人一起运行，以便可以并行执行回调

这通常是用' gunicorn '完成的，使用类似的语法:
```bash
gunicorn --workers 4 app:server
```

`app` 指的是一个名为`app.py`的文件，`server`指的是该文件中名为`server`的变量:`server`: `server = app.server`


当Dash应用程序在多个工作人员之间运行时，它们的内存不会被共享。这意味着，如果您在一个回调中修改了全局变量，该修改将不会应用到其他工作者/进程

* * *

这里是一个应用程序的草图，它不能可靠地工作，因为回调修改了一个全局变量，这是在它的作用域之外

 
 ```python
 df = pd.DataFrame({
  'student_id' : range(1, 11),
  'score' : [1, 5, 2, 5, 2, 3, 1, 5, 1, 5]
})

app.layout = html.Div([
	dcc.Dropdown(list(range(1, 6)), 1, id='score'),
	'was scored by this many students:',
	html.Div(id='output'),
])

@callback(Output('output', 'children'), Input('score', 'value'))
def update_output(value):
	global df
	df = df[df['score'] == value]
	return len(df)
 ```


回调在第一次调用时返回正确的输出，但是一旦修改了全局' df '变量，使用该数据框的任何后续回调都不再使用原始数据
要改进这个应用程序，可以将过滤后的数据框重新分配给回调函数中的一个新变量，如下所示，或者遵循本指南下一部分概述的策略之一


```python
df = pd.DataFrame({
  'student_id' : range(1, 11),
  'score' : [1, 5, 2, 5, 2, 3, 1, 5, 1, 5]
})

app.layout = html.Div([
    dcc.Dropdown(list(range(1, 6)), 1, id='score'),
	'was scored by this many students:',
	html.Div(id='output'),
])

@callback(Output('output', 'children'), Input('score', 'value'))
def update_output(value):
	filtered_df = df[df['score'] == value]
	return len(filtered_df)
```
 

## 存储共享数据

为了跨多个进程或服务器安全地共享数据，我们需要将数据存储在每个进程都可以访问的地方

有三个地方可以存储这些数据

  * 在用户的浏览器会话中, 使用 [dcc.Store](/dash-core-components/store)
  * 在磁盘上(例如在文件或数据库中)
  * 在服务器端内存(RAM)中，跨进程和服务器共享，例如Redis数据库。为此，Dash Enterprise包括[板载，一键式Redis数据库](/ Dash - Enterprise / Redis -database)

下面的示例说明了其中的一些方法

### Example 1 使用`dcc.Store`在浏览器中存储数据

将数据保存在用户浏览器的会话中:

  * 数据必须转换为字符串，如JSON或base64编码的二进制数据进行存储
  * 以这种方式缓存的数据只在用户当前会话中可用
    * 如果你打开一个新的浏览器窗口，应用程序的回调将总是重新计算数据。数据仅在同一会话内的回调之间缓存
    * 此方法不会增加应用程序的内存占用
    * 网络流量可能会有成本。如果在回调之间共享10MB的数据，那么该数据将在每个回调之间通过网络传输
    * 如果网络成本太高，那么提前计算聚合并传输它们。你的应用程序可能不会显示10MB的数据，它只会显示它的一个子集或聚合

下面的示例展示了利用dcc的一种常用方法。存储:如果处理一个数据集需要很长时间，并且不同的输出使用该数据集，`dcc.Store`可用于将处理后的数据存储为中间值，然后将其用作多个回调中的输入以生成不同的输出。这样，昂贵的数据处理步骤只在一个回调中执行一次，而不是在每个回调中多次重复相同的昂贵计算

```python
app.layout = html.Div([
    dcc.Graph(id='graph'),
    html.Table(id='table'),
    dcc.Dropdown(id='dropdown'),

    # dcc.Store stores the intermediate value
    dcc.Store(id='intermediate-value')
])

@callback(Output('intermediate-value', 'data'), Input('dropdown', 'value'))
def clean_data(value):
     # some expensive data processing step
     cleaned_df = slow_processing_step(value)

     # more generally, this line would be
     # json.dumps(cleaned_df)
     return cleaned_df.to_json(date_format='iso', orient='split')

@callback(Output('graph', 'figure'), Input('intermediate-value', 'data'))
def update_graph(jsonified_cleaned_data):

    # more generally, this line would be
    # json.loads(jsonified_cleaned_data)
    dff = pd.read_json(jsonified_cleaned_data, orient='split')

    figure = create_figure(dff)
    return figure

@callback(Output('table', 'children'), Input('intermediate-value', 'data'))
def update_table(jsonified_cleaned_data):
    dff = pd.read_json(jsonified_cleaned_data, orient='split')
    table = create_table(dff)
    return table
```


注意，在将数据放入存储之前，需要将其序列化为JSON字符串。还要注意处理后的数据如何存储在dcc中。
通过分配数据作为其输出来`dcc.Store` ，然后通过使用相同的' dcc，多个回调使用相同的数据。`dcc.Store` 作为输入


请注意此示例的前一个版本
这个例子过去是用“隐藏div”来实现的。我们不再推荐使用隐藏div方法，而是推荐使用`dcc.Store`，
它将数据存储在用户浏览器的内存中，而不是浏览器的DOM中，从而使意图更加清晰


* * *

### Example 2  预先计算聚合

如果数据量很大，通过网络发送计算数据的成本可能会很高。在某些情况下，将这些数据序列化为JSON的成本也很高

在许多情况下，您的应用程序将只显示处理数据的子集或聚合。在这些情况下，您可以在数据处理回调中预先计算聚合，并将这些聚合传输到剩余的回调中
下面是一个简单的示例，说明如何将过滤或聚合的数据传输到多个回调，同样使用相同的`dcc.Store`


```python
@callback(
    Output('intermediate-value', 'data'),
    Input('dropdown', 'value'))
def clean_data(value):
     cleaned_df = slow_processing_step(value)

     # a few filter steps that compute the data
     # as it's needed in the future callbacks
     df_1 = cleaned_df[cleaned_df['fruit'] == 'apples']
     df_2 = cleaned_df[cleaned_df['fruit'] == 'oranges']
     df_3 = cleaned_df[cleaned_df['fruit'] == 'figs']

     datasets = {
         'df_1': df_1.to_json(orient='split', date_format='iso'),
         'df_2': df_2.to_json(orient='split', date_format='iso'),
         'df_3': df_3.to_json(orient='split', date_format='iso'),
     }

     return json.dumps(datasets)

@callback(
    Output('graph1', 'figure'),
    Input('intermediate-value', 'data'))
def update_graph_1(jsonified_cleaned_data):
    datasets = json.loads(jsonified_cleaned_data)
    dff = pd.read_json(datasets['df_1'], orient='split')
    figure = create_figure_1(dff)
    return figure

@callback(
    Output('graph2', 'figure'),
    Input('intermediate-value', 'data'))
def update_graph_2(jsonified_cleaned_data):
    datasets = json.loads(jsonified_cleaned_data)
    dff = pd.read_json(datasets['df_2'], orient='split')
    figure = create_figure_2(dff)
    return figure

@callback(
    Output('graph3', 'figure'),
    Input('intermediate-value', 'data'))
def update_graph_3(jsonified_cleaned_data):
    datasets = json.loads(jsonified_cleaned_data)
    dff = pd.read_json(datasets['df_3'], orient='split')
    figure = create_figure_3(dff)
    return figure
```


* * *

### Example 3 - Caching and Signaling

This example:

  * 使用Redis通过Flask-Cache在数据库的服务器端存储全局变量。此数据通过函数(' global store() ')访问，该函数的输出被缓存并通过其输入参数进行键控
  * 使用“dcc”。存储解决方案，以便在昂贵的计算完成时向其他回调发送信号
  * 注意，除了Redis，你也可以将其保存到文件系统中。看到< https://flask-caching.readthedocs。详情请参阅Io /en/latest/>
  * 这种信号是高性能的，因为它允许昂贵的计算只占用一个进程并执行一次。如果没有这种类型的信号，每个回调最终可能会并行计算昂贵的计算，锁定四个进程而不是一个进程

这种方法的另一个好处是，以后的会话可以使用预先计算的值。这将适用于具有少量输入的应用程序

Here's what this example looks like.

![Example of a Dash App that uses Caching](assets/images/gallery/caching.gif)

Here's what this example looks like in code:

```python
import os
import copy
import time

from dash import Dash, dcc, html, Input, Output, callback

import numpy as np
import pandas as pd
from flask_caching import Cache


external_stylesheets = [
    # Dash CSS
    'https://codepen.io/chriddyp/pen/bWLwgP.css',
    # Loading screen CSS
    'https://codepen.io/chriddyp/pen/brPBPO.css']

app = Dash(__name__, external_stylesheets=external_stylesheets)
server = app.server

CACHE_CONFIG = {
    # try 'FileSystemCache' if you don't want to setup redis
    'CACHE_TYPE': 'redis',
    'CACHE_REDIS_URL': os.environ.get('REDIS_URL', 'redis://localhost:6379')
}
cache = Cache()
cache.init_app(app.server, config=CACHE_CONFIG)

N = 100

df = pd.DataFrame({
    'category': (
        (['apples'] * 5 * N) +
        (['oranges'] * 10 * N) +
        (['figs'] * 20 * N) +
        (['pineapples'] * 15 * N)
    )
})
df['x'] = np.random.randn(len(df['category']))
df['y'] = np.random.randn(len(df['category']))

app.layout = html.Div([
    dcc.Dropdown(df['category'].unique(), 'apples', id='dropdown'),
    html.Div([
        html.Div(dcc.Graph(id='graph-1'), className="six columns"),
        html.Div(dcc.Graph(id='graph-2'), className="six columns"),
    ], className="row"),
    html.Div([
        html.Div(dcc.Graph(id='graph-3'), className="six columns"),
        html.Div(dcc.Graph(id='graph-4'), className="six columns"),
    ], className="row"),

    # signal value to trigger callbacks
    dcc.Store(id='signal')
])


# perform expensive computations in this "global store"
# these computations are cached in a globally available
# redis memory store which is available across processes
# and for all time.
@cache.memoize()
def global_store(value):
    # simulate expensive query
    print(f'Computing value with {value}')
    time.sleep(3)
    return df[df['category'] == value]


def generate_figure(value, figure):
    fig = copy.deepcopy(figure)
    filtered_dataframe = global_store(value)
    fig['data'][0]['x'] = filtered_dataframe['x']
    fig['data'][0]['y'] = filtered_dataframe['y']
    fig['layout'] = {'margin': {'l': 20, 'r': 10, 'b': 20, 't': 10} }
    return fig


@callback(Output('signal', 'data'), Input('dropdown', 'value'))
def compute_value(value):
    # compute value and send a signal when done
    global_store(value)
    return value


@callback(Output('graph-1', 'figure'), Input('signal', 'data'))
def update_graph_1(value):
    # generate_figure gets data from `global_store`.
    # the data in `global_store` has already been computed
    # by the `compute_value` callback and the result is stored
    # in the global redis cached
    return generate_figure(value, {
        'data': [{
            'type': 'scatter',
            'mode': 'markers',
            'marker': {
                'opacity': 0.5,
                'size': 14,
                'line': {'border': 'thin darkgrey solid'}
            }
        }]
    })


@callback(Output('graph-2', 'figure'), Input('signal', 'data'))
def update_graph_2(value):
    return generate_figure(value, {
        'data': [{
            'type': 'scatter',
            'mode': 'lines',
            'line': {'shape': 'spline', 'width': 0.5},
        }]
    })


@callback(Output('graph-3', 'figure'), Input('signal', 'data'))
def update_graph_3(value):
    return generate_figure(value, {
        'data': [{
            'type': 'histogram2d',
        }]
    })


@callback(Output('graph-4', 'figure'), Input('signal', 'data'))
def update_graph_4(value):
    return generate_figure(value, {
        'data': [{
            'type': 'histogram2dcontour',
        }]
    })


if __name__ == '__main__':
    app.run(debug=True, processes=6, threaded=False)
```


一些需要注意的事情

  * 我们通过使用3秒的系统睡眠来模拟一个昂贵的过程
  * 当应用程序加载时，渲染所有四个图形需要三秒钟
  * 初始计算只阻塞一个进程
  * 计算完成后，发送信号并并行执行四个回调以呈现图形。这些回调中的每一个都从“全局服务器端存储”中检索数据:Redis或文件系统缓存
  * 我们在“app.run”中设置了“processes=6”，以便多个回调可以并行执行。在生产环境中，这是通过类似于“$ gunicorn -workers 6 app:server”的方式完成的。如果您没有使用多个进程运行，那么您将不会看到图形并行更新，因为回调将串行更新
  * 由于我们使用多个进程运行服务器，我们将' thread '设置为' False '。一个Flask服务器不能同时是多进程和多线程的
  * 在下拉菜单中选择一个值，如果这个值在过去已经被选择过，那么它只需要不到三秒钟的时间。这是因为该值是从缓存中提取的
  * 同样，重新加载页面或在新窗口中打开应用程序也很快，因为初始状态和初始昂贵的计算已经计算过了

* * *

### Example 4 - 服务器上基于用户的会话数据

前面的示例以所有用户都可以访问的方式缓存计算

有时您可能希望将数据与用户会话隔离:一个用户的派生数据不应该更新下一个用户的派生数据。一种方法是将数据保存在dcc中。Store’，如第一个示例所示

另一种方法是将数据与会话ID一起保存在缓存中，然后使用该会话ID引用数据。由于数据保存在服务器上，而不是通过网络传输，因此这种方法通常比dcc更快。存储的方法

 _这个方法最初是在[达世币社区论坛的帖子](https://community.plotly.com/t/capture-window-tab-closing-event/7375/2?u=chriddyp)

This example:

  * 使用' flask caching '文件系统缓存缓存数据。你也可以保存到内存缓存或数据库，比如Redis
  * 将数据序列化为JSON
    * 如果您正在使用Pandas，请考虑使用Apache Arrow进行序列化，以获得更快的序列化速度，或者使用Plasma进行序列化，以获得更小的数据帧大小。社区线程(https://community.plotly.com/t/fast-way-to-share-data-between-callbacks/8024/2
  * 将会话数据保存到预期的并发用户数。这可以防止缓存被数据过度填充
  * 为每个会话创建唯一的会话id，并将其存储为' dcc '的数据。存储在每个页面加载。这意味着每个用户会话在dcc中都有唯一的数据。存储在他们的页面上

> 注意:与所有向客户端发送数据的示例一样，请注意这些会话不一定是安全的或加密的。这些会话id可能容易受到[会话固定](https://en.wikipedia.org/wiki/Session固定)类型的攻击

Here's what this example looks like in code:

```python
from dash import Dash, dcc, html, Input, Output, callback

import datetime
from flask_caching import Cache
import pandas as pd
import time
import uuid

external_stylesheets = [
    # Dash CSS
    'https://codepen.io/chriddyp/pen/bWLwgP.css',
    # Loading screen CSS
    'https://codepen.io/chriddyp/pen/brPBPO.css']

app = Dash(__name__, external_stylesheets=external_stylesheets)
cache = Cache(app.server, config={
    'CACHE_TYPE': 'redis',
    # Note that filesystem cache doesn't work on systems with ephemeral
    # filesystems like Heroku.
    'CACHE_TYPE': 'filesystem',
    'CACHE_DIR': 'cache-directory',

    # should be equal to maximum number of users on the app at a single time
    # higher numbers will store more data in the filesystem / redis cache
    'CACHE_THRESHOLD': 200
})


def get_dataframe(session_id):
    @cache.memoize()
    def query_and_serialize_data(session_id):
        # expensive or user/session-unique data processing step goes here

        # simulate a user/session-unique data processing step by generating
        # data that is dependent on time
        now = datetime.datetime.now()

        # simulate an expensive data processing task by sleeping
        time.sleep(3)

        df = pd.DataFrame({
            'time': [
                str(now - datetime.timedelta(seconds=15)),
                str(now - datetime.timedelta(seconds=10)),
                str(now - datetime.timedelta(seconds=5)),
                str(now)
            ],
            'values': ['a', 'b', 'a', 'c']
        })
        return df.to_json()

    return pd.read_json(query_and_serialize_data(session_id))


def serve_layout():
    session_id = str(uuid.uuid4())

    return html.Div([
        dcc.Store(data=session_id, id='session-id'),
        html.Button('Get data', id='get-data-button'),
        html.Div(id='output-1'),
        html.Div(id='output-2')
    ])


app.layout = serve_layout


@callback(Output('output-1', 'children'),
              Input('get-data-button', 'n_clicks'),
              Input('session-id', 'data'))
def display_value_1(value, session_id):
    df = get_dataframe(session_id)
    return html.Div([
        'Output 1 - Button has been clicked {} times'.format(value),
        html.Pre(df.to_csv())
    ])


@callback(Output('output-2', 'children'),
              Input('get-data-button', 'n_clicks'),
              Input('session-id', 'data'))
def display_value_2(value, session_id):
    df = get_dataframe(session_id)
    return html.Div([
        'Output 2 - Button has been clicked {} times'.format(value),
        html.Pre(df.to_csv())
    ])


if __name__ == '__main__':
    app.run(debug=True)
```



![Example of a Dash App that uses User Session
Caching](assets/images/gallery/user-session-caching.gif)

在这个例子中有三件事需要注意:

  * 当我们检索数据时，数据框的时间戳不会更新。该数据作为用户会话的一部分被缓存
  * 最初检索数据需要三秒钟，但后续查询是即时的，因为数据已被缓存
  * 第二个会话显示与第一个会话不同的数据:回调之间共享的数据被隔离到单个用户会话中

Questions? Discuss these examples on the [Dash Community
Forum](https://community.plotly.com/c/dash).

